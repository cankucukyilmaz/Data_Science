{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((244, 244)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def mean_std_calculator(loader):\n",
    "    mean, std = 0.0, 0.0\n",
    "\n",
    "    for image, _ in loader:\n",
    "        batch_samples = image.size(0)\n",
    "        images = image.view(batch_samples, image.size(1), -1)\n",
    "        mean += images.mean(2).sum()\n",
    "        std += images.std(2).sum()\n",
    "\n",
    "    mean /= len(loader.dataset)\n",
    "    std /= len(loader.dataset)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(cwd, \"data/train\")\n",
    "test_path = os.path.join(cwd, \"data/test\")\n",
    "models_folder = \"models\"\n",
    "model_path = os.path.join(models_folder, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "KERNEL = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(train_path, transform=base_transform)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# mean, std = mean_std_calculator(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((244, 244)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.Normalize((0.5,)*3, (0.5,)*3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((244, 244)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,)*3, (0.5,)*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(train_path, transform=train_transform)\n",
    "test_data = datasets.ImageFolder(test_path, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['butterfly',\n",
       " 'cat',\n",
       " 'chicken',\n",
       " 'cow',\n",
       " 'dog',\n",
       " 'elephant',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'spider',\n",
       " 'squirrel']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = train_data.class_to_idx.keys()\n",
    "list(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, KERNEL)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 15, KERNEL)\n",
    "        self.fc1 = nn.Linear(15 * 58 * 58, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 2.371 accuracy: 12.50%\n",
      "[1,    20] loss: 2.302 accuracy: 11.88%\n",
      "[2,    10] loss: 2.293 accuracy: 18.75%\n",
      "[2,    20] loss: 2.292 accuracy: 7.50%\n",
      "[3,    10] loss: 2.246 accuracy: 10.62%\n",
      "[3,    20] loss: 2.257 accuracy: 13.75%\n",
      "[4,    10] loss: 2.136 accuracy: 24.38%\n",
      "[4,    20] loss: 2.255 accuracy: 16.88%\n",
      "[5,    10] loss: 2.249 accuracy: 15.62%\n",
      "[5,    20] loss: 2.094 accuracy: 21.25%\n",
      "[6,    10] loss: 2.105 accuracy: 21.25%\n",
      "[6,    20] loss: 2.144 accuracy: 20.00%\n",
      "[7,    10] loss: 2.140 accuracy: 18.12%\n",
      "[7,    20] loss: 2.098 accuracy: 28.12%\n",
      "[8,    10] loss: 2.049 accuracy: 20.62%\n",
      "[8,    20] loss: 1.908 accuracy: 28.75%\n",
      "[9,    10] loss: 1.878 accuracy: 35.00%\n",
      "[9,    20] loss: 2.071 accuracy: 25.00%\n",
      "[10,    10] loss: 1.927 accuracy: 33.12%\n",
      "[10,    20] loss: 1.886 accuracy: 35.62%\n",
      "[11,    10] loss: 1.670 accuracy: 42.50%\n",
      "[11,    20] loss: 1.841 accuracy: 30.00%\n",
      "[12,    10] loss: 1.687 accuracy: 39.38%\n",
      "[12,    20] loss: 1.638 accuracy: 44.38%\n",
      "[13,    10] loss: 1.486 accuracy: 51.88%\n",
      "[13,    20] loss: 1.584 accuracy: 45.62%\n",
      "[14,    10] loss: 1.336 accuracy: 54.37%\n",
      "[14,    20] loss: 1.699 accuracy: 43.75%\n",
      "[15,    10] loss: 1.381 accuracy: 51.88%\n",
      "[15,    20] loss: 1.655 accuracy: 45.00%\n",
      "[16,    10] loss: 1.379 accuracy: 50.00%\n",
      "[16,    20] loss: 1.472 accuracy: 48.12%\n",
      "[17,    10] loss: 1.227 accuracy: 55.62%\n",
      "[17,    20] loss: 1.163 accuracy: 62.50%\n",
      "[18,    10] loss: 0.953 accuracy: 66.88%\n",
      "[18,    20] loss: 1.422 accuracy: 49.38%\n",
      "[19,    10] loss: 1.073 accuracy: 64.38%\n",
      "[19,    20] loss: 0.999 accuracy: 66.88%\n",
      "[20,    10] loss: 1.050 accuracy: 63.75%\n",
      "[20,    20] loss: 0.841 accuracy: 70.62%\n",
      "[21,    10] loss: 0.807 accuracy: 75.00%\n",
      "[21,    20] loss: 0.793 accuracy: 71.25%\n",
      "[22,    10] loss: 0.579 accuracy: 83.12%\n",
      "[22,    20] loss: 0.676 accuracy: 77.50%\n",
      "[23,    10] loss: 0.736 accuracy: 75.62%\n",
      "[23,    20] loss: 0.724 accuracy: 76.88%\n",
      "[24,    10] loss: 0.642 accuracy: 76.25%\n",
      "[24,    20] loss: 0.765 accuracy: 76.88%\n",
      "[25,    10] loss: 0.732 accuracy: 75.00%\n",
      "[25,    20] loss: 0.805 accuracy: 74.38%\n",
      "[26,    10] loss: 0.690 accuracy: 79.38%\n",
      "[26,    20] loss: 0.810 accuracy: 73.75%\n",
      "[27,    10] loss: 0.435 accuracy: 86.25%\n",
      "[27,    20] loss: 0.451 accuracy: 85.00%\n",
      "[28,    10] loss: 0.465 accuracy: 84.38%\n",
      "[28,    20] loss: 0.417 accuracy: 85.62%\n",
      "[29,    10] loss: 0.520 accuracy: 81.88%\n",
      "[29,    20] loss: 0.616 accuracy: 78.75%\n",
      "[30,    10] loss: 0.444 accuracy: 86.25%\n",
      "[30,    20] loss: 0.533 accuracy: 83.12%\n",
      "[31,    10] loss: 0.323 accuracy: 90.62%\n",
      "[31,    20] loss: 0.468 accuracy: 85.62%\n",
      "[32,    10] loss: 0.394 accuracy: 86.25%\n",
      "[32,    20] loss: 0.405 accuracy: 90.62%\n",
      "[33,    10] loss: 0.324 accuracy: 90.62%\n",
      "[33,    20] loss: 0.320 accuracy: 90.62%\n",
      "[34,    10] loss: 0.386 accuracy: 90.00%\n",
      "[34,    20] loss: 0.293 accuracy: 91.88%\n",
      "[35,    10] loss: 0.361 accuracy: 90.62%\n",
      "[35,    20] loss: 0.228 accuracy: 92.50%\n",
      "[36,    10] loss: 0.252 accuracy: 93.12%\n",
      "[36,    20] loss: 0.216 accuracy: 95.00%\n",
      "[37,    10] loss: 0.337 accuracy: 89.38%\n",
      "[37,    20] loss: 0.240 accuracy: 91.25%\n",
      "[38,    10] loss: 0.302 accuracy: 89.38%\n",
      "[38,    20] loss: 0.438 accuracy: 86.25%\n",
      "[39,    10] loss: 0.234 accuracy: 90.00%\n",
      "[39,    20] loss: 0.185 accuracy: 93.75%\n",
      "[40,    10] loss: 0.287 accuracy: 91.25%\n",
      "[40,    20] loss: 0.376 accuracy: 88.75%\n",
      "[41,    10] loss: 0.177 accuracy: 96.25%\n",
      "[41,    20] loss: 0.174 accuracy: 95.62%\n",
      "[42,    10] loss: 0.221 accuracy: 93.12%\n",
      "[42,    20] loss: 0.276 accuracy: 92.50%\n",
      "[43,    10] loss: 0.181 accuracy: 94.38%\n",
      "[43,    20] loss: 0.158 accuracy: 95.00%\n",
      "[44,    10] loss: 0.117 accuracy: 96.25%\n",
      "[44,    20] loss: 0.166 accuracy: 95.62%\n",
      "[45,    10] loss: 0.111 accuracy: 97.50%\n",
      "[45,    20] loss: 0.109 accuracy: 96.25%\n",
      "[46,    10] loss: 0.111 accuracy: 95.00%\n",
      "[46,    20] loss: 0.075 accuracy: 97.50%\n",
      "[47,    10] loss: 0.106 accuracy: 96.25%\n",
      "[47,    20] loss: 0.118 accuracy: 95.62%\n",
      "[48,    10] loss: 0.063 accuracy: 98.75%\n",
      "[48,    20] loss: 0.071 accuracy: 98.12%\n",
      "[49,    10] loss: 0.069 accuracy: 97.50%\n",
      "[49,    20] loss: 0.069 accuracy: 97.50%\n",
      "[50,    10] loss: 0.030 accuracy: 100.00%\n",
      "[50,    20] loss: 0.136 accuracy: 95.62%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    running_total = 0\n",
    "    running_correct = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class index with the max score\n",
    "        running_total += labels.size(0)  # Update total number of samples\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if i%10 == 9:\n",
    "            avg_loss = running_loss / 10\n",
    "            avg_acc = (running_correct / running_total) * 100\n",
    "\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {avg_loss:.3f} accuracy: {avg_acc:.2f}%')\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "            running_total = 0\n",
    "\n",
    "    \n",
    "    avg_loss = running_loss/len(train_loader)\n",
    "    avg_acc = (running_correct/running_total) * 100\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 15, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=50460, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Net()\n",
    "test.load_state_dict(torch.load(model_path))\n",
    "test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(cwd + \"/lala.jpg\")\n",
    "input_tensor = test_transform(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
